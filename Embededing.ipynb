{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Each of the headings related to embeddings, specifically using the Word2Vec model from the Gensim library**"
      ],
      "metadata": {
        "id": "I-BtyCJAfKg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Traning Data**"
      ],
      "metadata": {
        "id": "PMcGTs2Th2td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample training data (a corpus of sentences)\n",
        "sentences = [\n",
        "    ['I', 'love', 'deep', 'learning'],\n",
        "    ['deep', 'learning', 'is', 'fun'],\n",
        "    ['natural', 'language', 'processing', 'is', 'a', 'branch', 'of', 'AI'],\n",
        "    ['Word2Vec', 'is', 'a', 'great', 'embedding', 'technique']\n",
        "]"
      ],
      "metadata": {
        "id": "hPpICPgGe4Fq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Context Window**"
      ],
      "metadata": {
        "id": "pf_EAWECiWc0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IkIGfbIDeiRO"
      },
      "outputs": [],
      "source": [
        "# Define the context window size\n",
        "context_window = 2  # Example window size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Model Training**"
      ],
      "metadata": {
        "id": "nz82gmUCifgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=50, window=context_window, min_count=1, sg=1)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"word2vec.model\")"
      ],
      "metadata": {
        "id": "BWiyJdpHijFc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Output (Word Embeddings)**\n"
      ],
      "metadata": {
        "id": "0XiRKWkoiptz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model (if needed)\n",
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "\n",
        "# Get the embedding for the word 'deep'\n",
        "vector = model.wv['deep']\n",
        "print(\"Embedding for 'deep':\", vector)"
      ],
      "metadata": {
        "id": "WKzKK1l-e33D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27f1fa3-f4bb-45b6-f944-398b8e96c1df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding for 'deep': [-0.01631583  0.0089916  -0.00827415  0.00164907  0.01699724 -0.00892435\n",
            "  0.009035   -0.01357392 -0.00709698  0.01879702 -0.00315531  0.00064274\n",
            " -0.00828126 -0.01536538 -0.00301602  0.00493959 -0.00177605  0.01106732\n",
            " -0.00548595  0.00452013  0.01091159  0.01669191 -0.00290748 -0.01841629\n",
            "  0.0087411   0.00114357  0.01488382 -0.00162657 -0.00527683 -0.01750602\n",
            " -0.00171311  0.00565313  0.01080286  0.01410531 -0.01140624  0.00371764\n",
            "  0.01217773 -0.0095961  -0.00621452  0.01359526  0.00326295  0.00037983\n",
            "  0.00694727  0.00043555  0.01923765  0.01012121 -0.01783478 -0.01408312\n",
            "  0.00180291  0.01278507]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentence\n",
        "sentence = \"I love deep learning\"\n",
        "\n",
        "# Context window of size 2\n",
        "context_window_size = 2\n",
        "\n",
        "# Tokenizing the sentence\n",
        "words = sentence.split()\n",
        "\n",
        "# Creating context windows\n",
        "context_windows = [\n",
        "    (words[max(0, i - context_window_size):min(len(words), i + context_window_size + 1)], words[i])\n",
        "    for i in range(len(words))\n",
        "]\n",
        "\n",
        "print(\"Context windows:\")\n",
        "for context, target in context_windows:\n",
        "    print(f\"Context: {context}, Target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHzoSLKafrUB",
        "outputId": "5f93a63e-971e-4e4e-f3a2-1f4d6a0ce031"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context windows:\n",
            "Context: ['I', 'love', 'deep'], Target: I\n",
            "Context: ['I', 'love', 'deep', 'learning'], Target: love\n",
            "Context: ['I', 'love', 'deep', 'learning'], Target: deep\n",
            "Context: ['love', 'deep', 'learning'], Target: learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Improved Performance:**\n",
        "Use the word embeddings in a machine learning task. Here, we'll create a simple example where we check the similarity between words.\n"
      ],
      "metadata": {
        "id": "JV504wjijK_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check similarity between words\n",
        "similarity = model.wv.similarity('deep', 'learning')\n",
        "print(\"Similarity between 'deep' and 'learning':\", similarity)\n",
        "\n",
        "# Find most similar words to 'deep'\n",
        "similar_words = model.wv.most_similar('deep')\n",
        "print(\"Words most similar to 'deep':\", similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuW4oPaDgE4B",
        "outputId": "903f3d39-3340-43fe-e2f9-715ae2b3eb5c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between 'deep' and 'learning': 0.011071963\n",
            "Words most similar to 'deep': [('I', 0.22978782653808594), ('technique', 0.12486250698566437), ('of', 0.08061248809099197), ('love', 0.07399576157331467), ('is', 0.04237300902605057), ('language', 0.018277151510119438), ('Word2Vec', 0.011398451402783394), ('learning', 0.011071980930864811), ('processing', 0.0013571369927376509), ('AI', -0.01201754529029131)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Semantic Understanding:**\n",
        "Illustrate how embeddings capture semantic relationships by showing vector arithmetic."
      ],
      "metadata": {
        "id": "hd9pCxoGjmzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of vector arithmetic: 'deep' - 'learning' + 'fun' â‰ˆ 'is'\n",
        "vector_deep = model.wv['deep']\n",
        "vector_learning = model.wv['learning']\n",
        "vector_fun = model.wv['fun']\n",
        "\n",
        "# Vector arithmetic\n",
        "result_vector = vector_deep - vector_learning + vector_fun\n",
        "\n",
        "# Find the word that is most similar to the result_vector\n",
        "most_similar_word = model.wv.similar_by_vector(result_vector, topn=1)\n",
        "print(\"Result of 'deep' - 'learning' + 'fun':\", most_similar_word)\n"
      ],
      "metadata": {
        "id": "OAO1QmzfjaQk",
        "outputId": "65b7eb5d-5125-46c3-aebc-98cad906c672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of 'deep' - 'learning' + 'fun': [('fun', 0.6047247648239136)]\n"
          ]
        }
      ]
    }
  ]
}